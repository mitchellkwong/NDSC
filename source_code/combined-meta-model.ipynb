{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mobilefull', 'beauty-nlp-data', 'mobile-nlp-data', 'fashion-nlp-data', 'beauty-nlp-model', 'fashionfull', 'ndsc-beginner', 'fashion-meta-model', 'mobile-meta-model']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "import os\n",
    "print(os.listdir(\"../input\"))\n",
    "\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_uuid": "69f8e8024bca67c73a92ef318ed8eaae4ca1e351"
   },
   "outputs": [],
   "source": [
    "def split_groups(df):\n",
    "    beauty = df[df.image_path.str.contains('beauty')]\n",
    "    fashion = df[df.image_path.str.contains('fashion')]\n",
    "    mobile = df[df.image_path.str.contains('mobile')]\n",
    "    \n",
    "    return beauty, fashion, mobile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "a4a058ff7635a34e70900724e453836d3132bc4c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# CNN base model\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.applications import Xception\n",
    "from keras.layers import Dense, Dropout\n",
    "\n",
    "def get_cnn(num_classes, weights = None):\n",
    "    if weights:\n",
    "        base = Xception(include_top = False, pooling = 'avg', classes = num_classes, weights = None)\n",
    "    else:\n",
    "        base = Xception(include_top = False, pooling = 'avg', classes = num_classes)\n",
    "\n",
    "    x = base.output\n",
    "    x = Dense(1024, activation = 'relu')(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    predictions = Dense(num_classes, activation = 'softmax')(x)\n",
    "    \n",
    "    cnn = Model(input = base.input, output = predictions)\n",
    "    if weights: cnn.load_weights(weights)\n",
    "        \n",
    "    cnn.compile(loss = 'categorical_crossentropy',\n",
    "              optimizer = 'adam',\n",
    "              metrics = ['accuracy'])\n",
    "    \n",
    "    return cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "# NLP base model\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Dropout\n",
    "\n",
    "def get_nlp(num_classes, num_features = 384, weights = None):\n",
    "    base = Input(shape = (num_features,))\n",
    "    x = Dense(1024, activation = 'relu')(base)\n",
    "    x = Dropout(0.3)(x)\n",
    "    predictions = Dense(num_classes, activation = 'softmax')(x)\n",
    "\n",
    "    nlp = Model(input = base, output = predictions)\n",
    "    if weights: nlp.load_weights(weights)\n",
    "\n",
    "    nlp.compile(loss = 'categorical_crossentropy',\n",
    "              optimizer = 'adam',\n",
    "              metrics = ['accuracy'])\n",
    "\n",
    "    return nlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "4198a9a3144017990aca1ad5d5423b00e296c448"
   },
   "outputs": [],
   "source": [
    "# Meta classifier\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import concatenate\n",
    "\n",
    "def get_meta(base_models, num_classes, weights = None):\n",
    "    x = concatenate([base.output for base in base_models])\n",
    "    x = Dense(128, activation = 'relu')(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    predictions = Dense(num_classes, activation = 'softmax')(x)\n",
    "\n",
    "    meta = Model(input = [base.input for base in base_models], output = predictions)\n",
    "    if weights: meta.load_weights(weights)\n",
    "\n",
    "    meta.compile(loss = 'categorical_crossentropy',\n",
    "               optimizer = 'adam',\n",
    "               metrics = ['accuracy'])\n",
    "\n",
    "    return meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "a684861d0506053ea01d59891ffde86e5aa2f4c9"
   },
   "outputs": [],
   "source": [
    "# Convenience constructor\n",
    "\n",
    "def get_models(num_classes, weights = dict()):\n",
    "    cnn = get_cnn(num_classes = num_classes, weights = weights.get('cnn', None))\n",
    "    nlp = get_nlp(num_classes = num_classes, weights = weights.get('nlp', None))\n",
    "    meta = get_meta([cnn, nlp], num_classes = num_classes, weights = weights.get('meta', None))\n",
    "    \n",
    "    return cnn, nlp, meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "990cfe8a8ca84441a6583de90cdb9484c3419570"
   },
   "outputs": [],
   "source": [
    "# Search directory for the best model weights\n",
    "\n",
    "import os\n",
    "import re\n",
    "\n",
    "pattern = r'(?P<name>.*?)_(?P<val_loss>.*?)-(?P<val_acc>.*?)\\.hdf5'\n",
    "def get_best_weights(directory, pattern = pattern):\n",
    "    best_loss = None\n",
    "    best_weights = None\n",
    "    \n",
    "    for weights in os.listdir(directory):\n",
    "        match = re.match(pattern, weights)\n",
    "        if match:\n",
    "            val_loss = float(match.group('val_loss'))\n",
    "            if (best_loss == None) or (val_loss <= best_loss):\n",
    "                best_loss = val_loss\n",
    "                best_weights = weights\n",
    "    \n",
    "    if best_weights:\n",
    "        return directory + best_weights\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "8a4ebe1827df6ec1a88f19fdd17630654c50df15"
   },
   "outputs": [],
   "source": [
    "# Data generator\n",
    "\n",
    "import spacy\n",
    "from keras.utils import Sequence\n",
    "from keras.applications.xception import preprocess_input\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "class MetaDataGenerator(Sequence):\n",
    "    def __init__(self, dataframe, directory, docvec, classes, batch_size = 32):\n",
    "        self.image_dir = directory        \n",
    "        self.image_name = dataframe.image_name\n",
    "        self.docvec = docvec\n",
    "        self.category = classes\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "    def __len__(self):\n",
    "        return int(np.ceil(self.image_name.shape[0] / self.batch_size))\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        lo = self.batch_size * index\n",
    "        hi = self.batch_size * index + self.batch_size\n",
    "        \n",
    "        cnn_input = self.image_name[lo:hi].apply(lambda f: imread(self.image_dir + f))\n",
    "        cnn_input = np.vstack([preprocess_input(img[np.newaxis,..., 0:3]) for img in cnn_input.values])\n",
    "        nlp_input = self.docvec[lo:hi]\n",
    "        \n",
    "        if isinstance(self.category, np.ndarray):\n",
    "            return [cnn_input, nlp_input], self.category[lo:hi]\n",
    "        else:\n",
    "            return [cnn_input, nlp_input]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "4645a7d58191d75d648466f3afbf15453de46a48"
   },
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_uuid": "4645a7d58191d75d648466f3afbf15453de46a48"
   },
   "outputs": [],
   "source": [
    "meta = pd.read_json('../input/ndsc-beginner/categories.json')\n",
    "beauty_class = [str(int(k)) for k in meta.Beauty.dropna().unique()]\n",
    "fashion_class = [str(int(k)) for k in meta.Fashion.dropna().unique()]\n",
    "mobile_class = [str(int(k)) for k in meta.Mobile.dropna().unique()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "d85ce6a7be028013b2237bb88320b1e9820cbdea"
   },
   "source": [
    "## Load models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_uuid": "4645a7d58191d75d648466f3afbf15453de46a48"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.4/xception_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "83689472/83683744 [==============================] - 1s 0us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:18: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:12: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n",
      "  if sys.path[0] == '':\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:12: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=Tensor(\"de...)`\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "beauty_weights = get_best_weights('../input/beauty-nlp-model/')\n",
    "beauty_cnn, beauty_nlp, beauty_meta = get_models(num_classes = len(beauty_class), weights = {'nlp': beauty_weights})\n",
    "\n",
    "fashion_weights = get_best_weights('../input/fashion-meta-model/')\n",
    "fashion_cnn, fashion_nlp, fashion_meta = get_models(num_classes = len(fashion_class), weights = {'meta': fashion_weights})\n",
    "\n",
    "mobile_weights = get_best_weights('../input/mobile-meta-model/')\n",
    "mobile_cnn, mobile_nlp, mobile_meta = get_models(num_classes = len(mobile_class), weights = {'meta': mobile_weights})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "22d1fe5c3408a98db82f66cd9ea8fd9ce22b85b4"
   },
   "source": [
    "## Generate predictions for each group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_uuid": "f2ca0c38e1f945668abd2aa02313124c0598a347"
   },
   "outputs": [],
   "source": [
    "beauty_Xte = np.load('../input/beauty-nlp-data/X_test.npy')\n",
    "beauty_pred = beauty_nlp.predict(beauty_Xte).argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_uuid": "f2ca0c38e1f945668abd2aa02313124c0598a347"
   },
   "outputs": [],
   "source": [
    "fashion_testgen = MetaDataGenerator(\n",
    "    dataframe = pd.read_csv('../input/fashionfull/fashion_test.csv'),\n",
    "    directory = '../input/fashionfull/fashion_image_resized/fashion_image_resized/test/',\n",
    "    docvec = np.load('../input/fashion-nlp-data/X_test.npy'),\n",
    "    classes = None,\n",
    ")\n",
    "\n",
    "fashion_pred = fashion_meta.predict_generator(fashion_testgen).argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_uuid": "813edd6582416f5c0f1b30e3eaac62578bc2b845"
   },
   "outputs": [],
   "source": [
    "# fashion_Xte = np.load('../input/fashion-nlp-data/X_test.npy')\n",
    "# fashion_pred = fashion_nlp.predict(fashion_Xte).argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_uuid": "f2ca0c38e1f945668abd2aa02313124c0598a347"
   },
   "outputs": [],
   "source": [
    "mobile_testgen = MetaDataGenerator(\n",
    "    dataframe = pd.read_csv('../input/mobilefull/mobile_test.csv'),\n",
    "    directory = '../input/mobilefull/mobile_image_resized/mobile_image_resized/test/',\n",
    "    docvec = np.load('../input/mobile-nlp-data/X_test.npy'),\n",
    "    classes = None,\n",
    ")\n",
    "\n",
    "mobile_pred = mobile_meta.predict_generator(mobile_testgen).argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_uuid": "97f10dc3de18172c175e8dff656db49a1cd086e2"
   },
   "outputs": [],
   "source": [
    "# mobile_Xte = np.load('../input/mobile-nlp-data/X_test.npy')\n",
    "# mobile_pred = mobile_nlp.predict(mobile_Xte).argmax(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "97aa79b8ad2bd8b7f41355464593d8f937ee81a0"
   },
   "source": [
    "## Aggregate group predictions into submission csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_uuid": "efddeee0abf760778b12052a56132fa89fa70f5a"
   },
   "outputs": [],
   "source": [
    "beauty, fashion, mobile = split_groups(pd.read_csv('../input/ndsc-beginner/test.csv'))\n",
    "\n",
    "predictions = pd.DataFrame({\n",
    "    'itemid': np.hstack([beauty.itemid.values,\n",
    "                         fashion.itemid.values, \n",
    "                         mobile.itemid.values]),\n",
    "    'Category': [*[beauty_class[x] for x in beauty_pred],\n",
    "                 *[fashion_class[x] for x in fashion_pred],\n",
    "                 *[mobile_class[x] for x in mobile_pred]]\n",
    "})\n",
    "\n",
    "predictions = pd.read_csv('../input/ndsc-beginner/test.csv').merge(predictions)\n",
    "predictions.to_csv('combined-meta-model.csv', columns = ['itemid', 'Category'], index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
